---
title: "STA 644 Project Report"
author: "Yaqian Cheng, Yulin Lei, Mengrun Li, Leonardo Shu"
date: "May 1, 2017"
output: pdf_document
---

\textbf{Introduction \& Goal} \
Our aim for this project was to explore the models concerning point reference data and observe how they performed on a scenario of interest to us. Specifically, we wanted to see how Gaussian Process Models and Thin Plate Splines could help us make use of bike trip data in the Bay Area by predicting the locations of where users would most likely start a trip from. In doing so we would be able to see which bike stations are the most popular (in demand) and whether there are other areas they could expand to in order to capture more potential customers.\
\
\textbf{Data Description} \
\
We downloaded the data from http://www.bayareabikeshare.com/open-data. There are two datasets that we mainly used recorded from 2014/09/01 to 2015/08/31 including station information(station ID, name, latitude, longitude, dockcount, city), trip information(time, start terminal, end terminal, duration in second). There are 70 bike stations located in 5 different Bay Area cities.

The target response variable we defined is the number of trips start from a specific bike station. We combined the two datasets and aggregated into year level, day of week and hour of day level of each station, respectively.
\

\textbf{Gaussian Process Model}

To fit Gaussian Process Model, we used `spLM` function from the package `spBayes`, where predictors are longitudes and latitude of those 70 stations and response variables are the average number of trips starting from those stations. We set `starting` parameter values according to the variogram, use default values for `tuning`, and choose `prior` parameters according to the `starting` parameter values.

To get the coordinates for prediction, we loaded an internal dataset in R which contained the geolocation information of the US and then selected all three counties of the Bay Area, ‘San Francisco’, ‘San Mateo’, and ‘Santa Clara’, combined them and transformed it into a polygon. After that, we sampled some points inside of these areas as prediction coordinates.

A raster is a spatial (geographic) data structure that divides a region into rectangles called 'cells' (or 'pixels') that can store one or more values for each of these cells. Such a data structure is also referred to as a 'grid'. After we got predicted values from fitted model with coordinates for prediction, we could fill in the raster and plot the result.


\textbf{Thin Plate Splines (TPS)} 

Observed data: \((x_i, y_i, z_i)\), where
we wish to predict the number of trips \(z_i\) given longitude \(x_i\) and latitude \(y_i\) for all \(i\)

The smoothing spline model in two dimensions:
\[ \underset{f(x,y)}{\arg\min} ~~ \sum_{i=1}^n (z_i-f(x_i,y_i))^2 + \lambda \int \int \left(\frac{\partial^2 f}{\partial x^2} + 2 \frac{\partial^2 f}{\partial x \, \partial y} + \frac{\partial^2 f}{\partial y^2} \right) dx\, dy\]

Solution:
\[ f(x,y) = \sum_{i=1}^n w_i ~ d(x_i,y_i)^2 \log d(x_i,y_i).  \]

To fit TPS model, we used `Tps` function from the package `fields`, where predictors are longitudes and latitudes of those 70 stations and response variables are the average number of trips starting from those stations. Then we used prediction coordinates, `pred_coords`, and the TPS model as input to predict the average number of trips, `trip_pred`.

\textbf{Model Fits and Interpretation}
Leo
